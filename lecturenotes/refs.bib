processing main.tex
{'koller2009probabilistic', 'Barahona1982', 'Liao2019a', 'Schuch2007', 'Liu2020g', 'Morgenstern1979', 'Boixo2017', 'Marinescu2019', 'Revels2016', 'Lucas2014', 'Morgenstern1980', 'Chen2017h', 'Erdelyi2001', 'Zhu2019b', 'Cheung1983', 'Obermeyer2019', 'Pan2019a', 'DeBeaudrap2020', 'Pednault', 'Fried2018', 'Schindler2020a', 'Gao2017b', 'Kschischang2001', 'Rush2020', 'Huang2020b', 'github', 'Robeva2019', 'Gray2020', 'maclagan2015introduction', 'Schutski2020', 'Han2018', 'Critch2014', 'Zhang2009', 'Luo2019a', 'blog', 'Johnson2011', 'Glasser', 'Guo2019d', 'valiant1979complexity', 'Kirkpatrick1983', 'Wang2014e', 'Garcia-Saez', 'Dumitrescu2018a', 'Vannimenus1977', 'Kourtis2018', 'Wang1988', 'Rams2018a', 'Biamonte2015', 'treewidth', 'Villalonga', 'Dudek2019', 'Aji2000', 'mezard2009information', 'chen2018classical'} 54
@article{Barahona1982,
abstract = {In a spin glass with Ising spins, the problems of computing the magnetic partition function and finding a ground state are studied. In a finite two-dimensional lattice these problems can be solved by algorithms that require a number of steps bounded by a polynomial function of the size of the lattice. In contrast to this fact, the same problems are shown to belong to the class of w-hard problems, both in the two-dimensional case within a magnetic field, and in the three-dimensional case. Np-hardness of a problem suggests that it is very unlikely that a polynomial algorithm could exist to solve it.},
author = {Barahona, F.},
doi = {10.1088/0305-4470/15/10/028},
file = {:Users/leiwang/Work/Others/Papers/F{\_}Barahona{\_}1982{\_}J.{\_}Phys.{\_}A{\_}{\_}Math.{\_}Gen.{\_}15{\_}028.pdf:pdf},
issn = {13616447},
journal = {J. Phys. A. Math. Gen.},
number = {10},
pages = {3241--3253},
title = {{On the computational complexity of ising spin glass models}},
volume = {15},
year = {1982}
}

@article{Liao2019a,
abstract = {Differentiable programming is a fresh programming paradigm which composes parameterized algorithmic components and optimizes them using gradient search. The concept emerges from deep learning but is not limited to training neural networks. We present the theory and practice of programming tensor network algorithms in a fully differentiable way. By formulating the tensor network algorithm as a computation graph, one can compute higher-order derivatives of the program accurately and efficiently using automatic differentiation. We present essential techniques to differentiate through the tensor networks contraction algorithms, including numerical stable differentiation for tensor decompositions and efficient backpropagation through fixed-point iterations. As a demonstration, we compute the specific heat of the Ising model directly by taking the second-order derivative of the free energy obtained in the tensor renormalization group calculation. Next, we perform gradient-based variational optimization of infinite projected entangled pair states for the quantum antiferromagnetic Heisenberg model and obtain state-of-the-art variational energy and magnetization with moderate efforts. Differentiable programming removes laborious human efforts in deriving and implementing analytical gradients for tensor network programs, which opens the door to more innovations in tensor network algorithms and applications.},
archivePrefix = {arXiv},
arxivId = {1903.09650},
author = {Liao, Hai-Jun and Liu, Jin-Guo and Wang, Lei and Xiang, Tao},
doi = {10.1103/PhysRevX.9.031041},
eprint = {1903.09650},
file = {:Users/leiwang/Work/Others/Papers/PhysRevX.9.031041.pdf:pdf},
issn = {21603308},
journal = {Phys. Rev. X},
keywords = {computational physics,condensed,doi:10.1103/PhysRevX.9.031041 url:https://doi.org/},
number = {3},
pages = {31041},
publisher = {American Physical Society},
title = {{Differentiable Programming Tensor Networks}},
url = {https://doi.org/10.1103/PhysRevX.9.031041},
volume = {9},
year = {2019}
}

@article{Schuch2007,
abstract = {We determine the computational power of preparing projected entangled pair states (PEPS), as well as the complexity of classically simulating them, and generally the complexity of contracting tensor networks. While creating PEPS allows us to solve PP problems, the latter two tasks are both proven to be {\#}P-complete. We further show how PEPS can be used to approximate ground states of gapped Hamiltonians and that creating them is easier than creating arbitrary PEPS. The main tool for our proofs is a duality between PEPS and postselection which allows us to use existing results from quantum complexity. {\textcopyright} 2007 The American Physical Society.},
author = {Schuch, Norbert and Wolf, Michael M. and Verstraete, Frank and Cirac, J. Ignacio},
doi = {10.1103/PhysRevLett.98.140506},
file = {:Users/leiwang/Work/Others/Papers/PhysRevLett.98.140506.pdf:pdf},
issn = {00319007},
journal = {Phys. Rev. Lett.},
number = {14},
pages = {140506},
title = {{Computational complexity of projected entangled pair states}},
volume = {98},
year = {2007}
}

@article{Liu2020g,
abstract = {This paper considers the source-to-source automatic differentiation (AD) in a reversible language. We start by reviewing the limitations of traditional AD frameworks. To solve the issues in these frameworks, we developed a reversible eDSL NiLang in Julia that can differentiate a general program while being compatible with Julia's ecosystem. It empowers users the flexibility to tradeoff time, space, and energy so that one can use it to obtain gradients and Hessians ranging for elementary mathematical functions, sparse matrix operations, and linear algebra that are widely used in scientific programming. We demonstrate that a source-to-source AD framework can achieve the state-of-the-art performance by showing and benchmarking several examples. Finally, we will discuss the challenges that we face towards rigorous reversible programming, mainly from the instruction and hardware perspective.},
archivePrefix = {arXiv},
arxivId = {2003.04617},
author = {Liu, Jin-Guo and Zhao, Taine},
eprint = {2003.04617},
file = {:Users/leiwang/Work/Others/Papers/2003.04617.pdf:pdf},
title = {{Differentiate Everything with a Reversible Programming Language}},
url = {http://arxiv.org/abs/2003.04617},
year = {2020}
}

@article{Morgenstern1979,
  title = {Evidence Against Spin-Glass Order in the Two-Dimensional Random-Bond Ising Model},
  author = {Morgenstern, I. and Binder, K.},
  journal = {Phys. Rev. Lett.},
  volume = {43},
  issue = {21},
  pages = {1615--1618},
  numpages = {0},
  year = {1979},
  month = {Nov},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.43.1615},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.43.1615}
}


@article{Boixo2017,
abstract = {Near term quantum computers with a high quantity (around 50) and quality (around 0.995 fidelity for two-qubit gates) of qubits will approximately sample from certain probability distributions beyond the capabilities of known classical algorithms on state-of-the-art computers, achieving the first milestone of so-called quantum supremacy. This has stimulated recent progress in classical algorithms to simulate quantum circuits. Classical simulations are also necessary to approximate the fidelity of multiqubit quantum computers using cross entropy benchmarking. Here we present numerical results of a classical simulation algorithm to sample universal random circuits, on a single workstation, with more qubits and depth than previously reported. For example, circuits with {\$}5 \backslashtimes 9{\$} qubits of depth 37, {\$}7 \backslashtimes 8{\$} qubits of depth 27, and {\$}10 \backslashtimes (\backslashkappa {\textgreater} 10){\$}) qubits of depth 19 are all easy to sample. We also show up to what depth the sampling, or estimation of observables, is trivially parallelizable. The algorithm is related to the "Feynmann path" method to simulate quantum circuits. For low-depth circuits, the algorithm scales exponentially in the depth times the smaller lateral dimension, or the treewidth, as explained in Boixo et. al., and therefore confirms the bounds in that paper. In particular, circuits with {\$}7 \backslashtimes 7{\$} qubits and depth 40 remain currently out of reach. Follow up work on a supercomputer environment will tighten this bound.},
archivePrefix = {arXiv},
arxivId = {1712.05384},
author = {Boixo, Sergio and Isakov, Sergei V. and Smelyanskiy, Vadim N. and Neven, Hartmut},
eprint = {1712.05384},
file = {:Users/leiwang/Work/Others/Papers/1712.05384.pdf:pdf},
title = {{Simulation of low-depth quantum circuits as complex undirected graphical models}},
url = {http://arxiv.org/abs/1712.05384},
year = {2017}
}

@misc{Marinescu2019_,
abstract = {We introduce {\#}opt, a new inference task for graphical models which calls for counting the number of optimal solutions of the model. We describe a novel variable elimination based approach for solving this task, as well as a depth-first branch and bound algorithm that traverses the AND/OR search space of the model. The key feature of the proposed algorithms is that their complexity is exponential in the induced width of the model only. It does not depend on the actual number of optimal solutions. Our empirical evaluation on various benchmarks demonstrates the effectiveness of the proposed algorithms compared with existing depth-first and best-first search based approaches that enumerate explicitly the optimal solutions.},
author = {Marinescu, Radu and Dechter, Rina},
booktitle = {Adv. Neural Inf. Process. Syst. 32},
number = {NeurIPS},
pages = {12091--12101},
title = {{Counting the Optimal Solutions in Graphical Models}},
url = {http://papers.nips.cc/paper/9379-counting-the-optimal-solutions-in-graphical-models},
year = {2019}
}

@article{Marinescu2019,
abstract = {We introduce {\#}opt, a new inference task for graphical models which calls for counting the number of optimal solutions of the model. We describe a novel variable elimination based approach for solving this task, as well as a depth-first branch and bound algorithm that traverses the AND/OR search space of the model. The key feature of the proposed algorithms is that their complexity is exponential in the induced width of the model only. It does not depend on the actual number of optimal solutions. Our empirical evaluation on various benchmarks demonstrates the effectiveness of the proposed algorithms compared with existing depth-first and best-first search based approaches that enumerate explicitly the optimal solutions.},
author = {Marinescu, Radu and Dechter, Rina},
journal = {Adv. Neural Inf. Process. Syst.},
volume = {32},
number = {NeurIPS},
pages = {12091--12101},
title = {{Counting the Optimal Solutions in Graphical Models}},
url = {http://papers.nips.cc/paper/9379-counting-the-optimal-solutions-in-graphical-models},
year = {2019}
}

@article{Revels2016,
abstract = {We present ForwardDiff, a Julia package for forward-mode automatic differentiation (AD) featuring performance competitive with low-level languages like C++. Unlike recently developed AD tools in other popular high-level languages such as Python and MATLAB, ForwardDiff takes advantage of just-in-time (JIT) compilation to transparently recompile AD-unaware user code, enabling efficient support for higher-order differentiation and differentiation using custom number types (including complex numbers). For gradient and Jacobian calculations, ForwardDiff provides a variant of vector-forward mode that avoids expensive heap allocation and makes better use of memory bandwidth than traditional vector mode. In our numerical experiments, we demonstrate that for nontrivially large dimensions, ForwardDiff's gradient computations can be faster than a reverse-mode implementation from the Python-based autograd package. We also illustrate how ForwardDiff is used effectively within JuMP, a modeling language for optimization. According to our usage statistics, 41 unique repositories on GitHub depend on ForwardDiff, with users from diverse fields such as astronomy, optimization, finite element analysis, and statistics. This document is an extended abstract that has been accepted for presentation at the AD2016 7th International Conference on Algorithmic Differentiation.},
archivePrefix = {arXiv},
arxivId = {1607.07892},
author = {Revels, Jarrett and Lubin, Miles and Papamarkou, Theodore},
eprint = {1607.07892},
file = {:Users/leiwang/Work/Others/Papers/1607.07892.pdf:pdf},
title = {{Forward-Mode Automatic Differentiation in Julia}},
url = {http://arxiv.org/abs/1607.07892},
year = {2016}
}

@article{Lucas2014,
abstract = {We provide Ising formulations for many NP-complete and NP-hard problems, including all of Karp's 21 NP-complete problems. This collects and extends mappings to the Ising model from partitioning, covering, and satisfiability. In each case, the required number of spins is at most cubic in the size of the problem. This work may be useful in designing adiabatic quantum optimization algorithms.},
archivePrefix = {arXiv},
arxivId = {1302.5843},
author = {Lucas, Andrew},
doi = {10.3389/fphy.2014.00005},
eprint = {1302.5843},
file = {:Users/leiwang/Library/Application Support/Mendeley Desktop/Downloaded/Lucas, Optimization - 2014 - Ising formulations of many NP problems.pdf:pdf},
issn = {2296424X},
journal = {Front. Phys.},
keywords = {Adiabatic quantum computation,Algorithms,Complexity theory,NP,Spin glasses},
number = {February},
pages = {5},
title = {{Ising formulations of many NP problems}},
volume = {2},
year = {2014}
}


@article{Morgenstern1980,
  title = {Magnetic correlations in two-dimensional spin-glasses},
  author = {Morgenstern, I. and Binder, K.},
  journal = {Phys. Rev. B},
  volume = {22},
  issue = {1},
  pages = {288--303},
  numpages = {0},
  year = {1980},
  month = {Jul},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.22.288},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.22.288}
}


@article{Chen2017h,
  title = {Equivalence of restricted Boltzmann machines and tensor network states},
  author = {Chen, Jing and Cheng, Song and Xie, Haidong and Wang, Lei and Xiang, Tao},
  journal = {Phys. Rev. B},
  volume = {97},
  issue = {8},
  pages = {085104},
  numpages = {16},
  year = {2018},
  month = {Feb},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.97.085104},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.97.085104}
}

@article{Zhu2019b,
abstract = {No. To illustrate that tensor renormalization group methods are poorly suited for frustrated magnetic systems, we study the thermodynamic properties of the two-dimensional Edwards-Anderson Ising spin-glass model on a square lattice. We show that the limited precision of standard 64-bit data types and not a small cut-off parameter is the main reason for unphysical negative partition function values in spin glasses.},
archivePrefix = {arXiv},
arxivId = {1903.07721},
author = {Zhu, Zheng and Katzgraber, Helmut G.},
eprint = {1903.07721},
file = {:Users/leiwang/Work/Others/Papers/1903.07721.pdf:pdf},
title = {{Do tensor renormalization group methods work for frustrated spin systems?}},
url = {http://arxiv.org/abs/1903.07721},
year = {2019}
}

@article{Cheung1983_,
author = {Cheung, Ho-Fai and McMillan, William L},
file = {:Users/leiwang/Work/Others/Papers/H{\_}-F{\_}Cheung{\_}1983{\_}J.{\_}Phys.{\_}C {\_}Solid{\_}State{\_}Phys.{\_}16{\_}017.pdf:pdf},
title = {{Equilibrium properties of the two-dimensional random (+or-J) Ising model}},
year = {1983}
}
@article{cheung1983,
    title={Equilibrium properties of the two-dimensional random (+ or-J) Ising model},
    author={Cheung, H-F and McMillan, WL},
    journal={Journal of Physics C: Solid State Physics},
    volume={16},
    number={36},
    pages={7027},
    year={1983},
    publisher={IOP Publishing}
}

@article{Obermeyer2019,
abstract = {It is a significant challenge to design probabilistic programming systems that can accommodate a wide variety of inference strategies within a unified framework. Noting that the versatility of modern automatic differentiation frameworks is based in large part on the unifying concept of tensors, we describe a software abstraction for integration --functional tensors-- that captures many of the benefits of tensors, while also being able to describe continuous probability distributions. Moreover, functional tensors are a natural candidate for generalized variable elimination and parallel-scan filtering algorithms that enable parallel exact inference for a large family of tractable modeling motifs. We demonstrate the versatility of functional tensors by integrating them into the modeling frontend and inference backend of the Pyro programming language. In experiments we show that the resulting framework enables a large variety of inference strategies, including those that mix exact and approximate inference.},
archivePrefix = {arXiv},
arxivId = {1910.10775},
author = {Obermeyer, Fritz and Bingham, Eli and Jankowiak, Martin and Phan, Du and Chen, Jonathan P},
eprint = {1910.10775},
file = {:Users/leiwang/Work/Others/Papers/1910.10775.pdf:pdf},
title = {{Functional Tensors for Probabilistic Programming}},
url = {http://arxiv.org/abs/1910.10775},
year = {2019}
}

@article{DeBeaudrap2020,
abstract = {We provide a graphical treatment of SAT and $\backslash${\#}SAT on equal footing. Instances of $\backslash${\#}SAT can be represented as tensor networks in a standard way. These tensor networks are interpreted by diagrams of the ZH-calculus: a system to reason about tensors over {\$}\backslashmathbb{\{}C{\}}{\$} in terms of diagrams built from simple generators, in which computation may be carried out by $\backslash$emph{\{}transformations of diagrams alone{\}}. In general, nodes of ZH diagrams take parameters over {\$}\backslashmathbb{\{}C{\}}{\$} which determine the tensor coefficients; for the standard representation of $\backslash${\#}SAT instances, the coefficients take the value {\$}0{\$} or {\$}1{\$}. Then, by choosing the coefficients of a diagram to range over {\$}\backslashmathbb B{\$}, we represent the corresponding instance of SAT. Thus, by interpreting a diagram either over the boolean semiring or the complex numbers, we instantiate either the $\backslash$emph{\{}decision{\}} or $\backslash$emph{\{}counting{\}} version of the problem. We find that for classes known to be in P, such as {\$}2{\$}SAT and $\backslash${\#}XORSAT, the existence of appropriate rewrite rules allows for efficient simplification of the diagram, producing the solution in polynomial time. In contrast, for classes known to be NP-complete, such as {\$}3{\$}SAT, or $\backslash${\#}P-complete, such as $\backslash${\#}{\$}2{\$}SAT, the corresponding rewrite rules introduce hyperedges to the diagrams, in numbers which are not easily bounded above by a polynomial. This diagrammatic approach unifies the diagnosis of the complexity of CSPs and $\backslash${\#}CSPs and shows promise in aiding tensor network contraction-based algorithms.},
archivePrefix = {arXiv},
arxivId = {2004.06455},
author = {de Beaudrap, Niel and Kissinger, Aleks and Meichanetzidis, Konstantinos},
eprint = {2004.06455},
file = {:Users/leiwang/Library/Application Support/Mendeley Desktop/Downloaded/Beaudrap, Kissinger, Meichanetzidis - 2020 - Tensor Network Rewriting Strategies for Satisfiability and Counting.pdf:pdf},
title = {{Tensor Network Rewriting Strategies for Satisfiability and Counting}},
url = {http://arxiv.org/abs/2004.06455},
year = {2020}
}

@article{Pednault,
abstract = {With the current rate of progress in quantum computing technologies, systems with more than 50 qubits will soon become reality. Computing ideal quantum state amplitudes for devices of such and larger sizes is a fundamental step to assess their fidelity, but memory requirements for such calculations on classical computers grow exponentially. In this study, we present a new approach for this task that extends the boundaries of what can be computed on a classical system. We present results obtained from a calculation of the complete set of output amplitudes of a universal random circuit with depth 27 in a 2D lattice of {\$}7 \backslashtimes 7{\$} qubits, and an arbitrarily selected slice of {\$}2{\^{}}{\{}37{\}}{\$} amplitudes of a universal random circuit with depth 23 in a 2D lattice of {\$}8 \backslashtimes 7{\$} qubits. Combining our methodology with other decomposition techniques found in the literature, we show that we can simulate {\$}7 \backslashtimes 7{\$}-qubit random circuits to arbitrary depth by leveraging secondary storage. These calculations were thought to be impossible due to memory requirements; our methodology requires memory within the limits of existing classical computers.},
archivePrefix = {arXiv},
arxivId = {1710.05867},
author = {Pednault, Edwin and Gunnels, John A and Nannicini, Giacomo and Horesh, Lior and Magerlein, Thomas and Solomonik, Edgar and Draeger, Erik W and Holland, Eric T and Wisnieff, Robert},
eprint = {1710.05867},
file = {:Users/leiwang/Library/Application Support/Mendeley Desktop/Downloaded/Pednault et al. - 2017 - Breaking the 49-Qubit Barrier in the Simulation of Quantum Circuits.pdf:pdf},
title = {{Breaking the 49-Qubit Barrier in the Simulation of Quantum Circuits}},
url = {http://arxiv.org/abs/1710.05867},
year = {2017}
}

@article{Fried2018,
abstract = {Classical simulation of quantum computation is necessary for studying the numerical behavior of quantum algorithms, as there does not yet exist a large viable quantum computer on which to perform numerical tests. Tensor network (TN) contraction is an algorithmic method that can efficiently simulate some quantum circuits, often greatly reducing the computational cost over methods that simulate the full Hilbert space. In this study we implement a tensor network contraction program for simulating quantum circuits using multi-core compute nodes. We show simulation results for the Max-Cut problem on 3-through 7-regular graphs using the quantum approximate optimization algorithm (QAOA), successfully simulating up to 100 qubits. We test two different methods for generating the ordering of tensor index contractions: one is based on the tree decomposition of the line graph, while the other generates ordering using a straight-forward stochastic scheme. Through studying instances of QAOA circuits, we show the expected result that as the treewidth of the quantum circuit's line graph decreases, TN contraction becomes significantly more efficient than simulating the whole Hilbert space. The results in this work suggest that tensor contraction methods are superior only when simulating Max-Cut/QAOA with graphs of regularities approximately five and below. Insight into this point of equal computational cost helps one determine which simulation method will be more efficient for a given quantum circuit. The stochastic contraction method outperforms the line graph based method only when the time to calculate a reasonable tree decomposition is prohibitively expensive. Finally, we release our software package, qTorch (Quantum TensOR Contraction Handler), intended for general quantum circuit simulation. For a nontrivial subset of these quantum circuits, 50 to 100 qubits can easily be simulated on a single compute node.},
author = {Fried, E Schuyler and Sawaya, Nicolas P.D. and Cao, Yudong and Kivlichan, Ian D. and Romero, Jhonathan and Aspuru-Guzik, Al{\'{a}}n},
doi = {10.1371/journal.pone.0208510},
file = {:Users/leiwang/Work/Others/Papers/journal.pone.0208510.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS One},
number = {12},
pages = {1--20},
title = {{QTOrch: The quantum tensor contraction handler}},
volume = {13},
year = {2018}
}

@article{Schindler2020a,
abstract = {Contracting tensor networks is often computationally demanding. Well-designed contraction sequences can dramatically reduce the contraction cost. We explore the performance of simulated annealing and genetic algorithms, two common discrete optimization techniques, to this ordering problem. We benchmark their performance as well as that of the commonly-used greedy search on physically relevant tensor networks. Where computationally feasible, we also compare them with the optimal contraction sequence obtained by an exhaustive search. We find that the algorithms we consider consistently outperform a greedy search given equal computational resources, with an advantage that scales with tensor network size. We compare the obtained contraction sequences and identify signs of highly non-local optimization, with the more sophisticated algorithms sacrificing run-time early in the contraction for better overall performance.},
archivePrefix = {arXiv},
arxivId = {2001.08063},
author = {Schindler, Frank and Jermyn, Adam S},
eprint = {2001.08063},
file = {:Users/leiwang/Work/Others/Papers/2001.08063.pdf:pdf},
number = {2},
title = {{Algorithms for Tensor Network Contraction Ordering}},
url = {http://arxiv.org/abs/2001.08063},
year = {2020}
}

@article{Gao2017b,
abstract = {A central task in the field of quantum computing is to find applications where quantum computer could provide exponential speedup over any classical computer. Machine learning represents an important field with broad applications where quantum computer may offer significant speedup. Several quantum algorithms for discriminative machine learning have been found based on efficient solving of linear algebraic problems, with potential exponential speedup in runtime under the assumption of effective input from a quantum random access memory. In machine learning, generative models represent another large class which is widely used for both supervised and unsupervised learning. Here, we propose an efficient quantum algorithm for machine learning based on a quantum generative model. We prove that our proposed model is exponentially more powerful to represent probability distributions compared with classical generative models and has exponential speedup in training and inference at least for some instances under a reasonable assumption in computational complexity theory. Our result opens a new direction for quantum machine learning and offers a remarkable example in which a quantum algorithm shows exponential improvement over any classical algorithm in an important application field.},
archivePrefix = {arXiv},
arxivId = {1711.02038},
author = {Gao, Xun and Zhang, Zhengyu and Duan, Luming},
eprint = {1711.02038},
file = {:Users/leiwang/Work/Others/Papers/1711.02038.pdf:pdf},
title = {{An efficient quantum algorithm for generative machine learning}},
url = {http://arxiv.org/abs/1711.02038},
year = {2017}
}

@article{Kschischang2001,
abstract = {Algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of "local" functions, each of which depends on a subset of the variables. Such a factorization can be visualized with a bipartite graph that we call a factor graph. In this tutorial paper, we present a generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph. Following a single, simple computational rule, the sum-product algorithm computes - either exactly or approximately - various marginal functions derived from the global function. A wide variety of algorithms developed in artificial intelligence, signal processing, and digital communications can be derived as specific instances of the sum-product algorithm, including the forward/backward algorithm, the Viterbi algorithm, the iterative "turbo" decoding algorithm, Pearl's belief propagation algorithm for Bayesian networks, the Kalman filter, and certain fast Fourier transform (FFT) algorithms.},
author = {Kschischang, Frank R. and Frey, Brendan J. and Loeliger, Hans Andrea},
doi = {10.1109/18.910572},
file = {:Users/leiwang/Library/Application Support/Mendeley Desktop/Downloaded/Kschischang, Frey, Loeliger - 2001 - Factor graphs and the sum-product algorithm.pdf:pdf},
issn = {00189448},
journal = {IEEE Trans. Inf. Theory},
keywords = {Belief propagation,Factor graphs,Fast Fourier transform,Forward/backward algorithm,Graphical models,Iterative decoding,Kalman filtering,Marginalization,Sum-product algorithm,Tanner graphs,Viterbi algorithm},
number = {2},
pages = {498--519},
title = {{Factor graphs and the sum-product algorithm}},
volume = {47},
year = {2001}
}

@article{Rush2020,
abstract = {The literature on structured prediction for NLP describes a rich collection of distributions and algorithms over sequences, segmentations, alignments, and trees; however, these algorithms are difficult to utilize in deep learning frameworks. We introduce Torch-Struct, a library for structured prediction designed to take advantage of and integrate with vectorized, auto-differentiation based frameworks. Torch-Struct includes a broad collection of probabilistic structures accessed through a simple and flexible distribution-based API that connects to any deep learning model. The library utilizes batched, vectorized operations and exploits auto-differentiation to produce readable, fast, and testable code. Internally, we also include a number of general-purpose optimizations to provide cross-algorithm efficiency. Experiments show significant performance gains over fast baselines and case-studies demonstrate the benefits of the library. Torch-Struct is available at https://github.com/harvardnlp/pytorch-struct.},
archivePrefix = {arXiv},
arxivId = {2002.00876},
author = {Rush, Alexander M},
eprint = {2002.00876},
file = {:Users/leiwang/Library/Application Support/Mendeley Desktop/Downloaded/Rush - 2018 - Torch-Struct Deep Structured Prediction Library.pdf:pdf},
title = {{Torch-Struct: Deep Structured Prediction Library}},
url = {http://arxiv.org/abs/2002.00876},
year = {2020}
}

@article{Huang2020b,
abstract = {It is believed that random quantum circuits are difficult to simulate classically. These have been used to demonstrate quantum supremacy: the execution of a computational task on a quantum computer that is infeasible for any classical computer. The task underlying the assertion of quantum supremacy by Arute et al. (Nature, 574, 505--510 (2019)) was initially estimated to require Summit, the world's most powerful supercomputer today, approximately 10,000 years. The same task was performed on the Sycamore quantum processor in only 200 seconds. In this work, we present a tensor network-based classical simulation algorithm. Using a Summit-comparable cluster, we estimate that our simulator can perform this task in less than 20 days. On moderately-sized instances, we reduce the runtime from years to minutes, running several times faster than Sycamore itself. These estimates are based on explicit simulations of parallel subtasks, and leave no room for hidden costs. The simulator's key ingredient is identifying and optimizing the "stem" of the computation: a sequence of pairwise tensor contractions that dominates the computational cost. This orders-of-magnitude reduction in classical simulation time, together with proposals for further significant improvements, indicates that achieving quantum supremacy may require a period of continuing quantum hardware developments without an unequivocal first demonstration.},
archivePrefix = {arXiv},
arxivId = {2005.06787},
author = {Huang, Cupjin and Zhang, Fang and Newman, Michael and Cai, Junjie and Gao, Xun and Tian, Zhengxiong and Wu, Junyin and Xu, Haihong and Yu, Huanjun and Yuan, Bo and Szegedy, Mario and Shi, Yaoyun and Chen, Jianxin},
eprint = {2005.06787},
file = {:Users/leiwang/Library/Application Support/Mendeley Desktop/Downloaded/Huang et al. - 2020 - Classical Simulation of Quantum Supremacy Circuits.pdf:pdf},
title = {{Classical Simulation of Quantum Supremacy Circuits}},
url = {http://arxiv.org/abs/2005.06787},
year = {2020}
}

@article{Robeva2019,
abstract = {In this article we show the duality between tensor networks and undirected graphical models with discrete variables. We study tensor networks on hypergraphs, which we call tensor hypernetworks. We show that the tensor hypernetwork on a hypergraph exactly corresponds to the graphical model given by the dual hypergraph.We translate various notions under duality. For example, marginalization in a graphical model is dual to contraction in the tensor network. Algorithms also translate under duality. We show that belief propagation corresponds to a known algorithm for tensor network contraction. This article is a reminder that the research areas of graphical models and tensor networks can benefit from interaction.},
archivePrefix = {arXiv},
arxivId = {1710.01437},
author = {Robeva, Elina and Seigal, Anna},
doi = {10.1093/imaiai/iay009},
eprint = {1710.01437},
file = {:Users/leiwang/Work/Others/Papers/iay009.pdf:pdf},
issn = {20498772},
journal = {Inf. Inference},
keywords = {Belief propagation,Graphical models,Hypergraphs,Tensor networks},
number = {2},
pages = {273--288},
title = {{Duality of graphical models and tensor networks}},
volume = {8},
year = {2019}
}

@article{Gray2020,
abstract = {Tensor networks represent the state-of-the-art in computational methods across many disciplines, including the classical simulation of quantum many-body systems and quantum circuits. Several applications of current interest give rise to tensor networks with irregular geometries. Finding the best possible contraction path for such networks is a central problem, with an exponential effect on computation time and memory footprint. In this work, we implement new randomized protocols that find very high quality contraction paths for arbitrary and large tensor networks. We test our methods on a variety of benchmarks, including the random quantum circuit instances recently implemented on Google quantum chips. We find that the paths obtained can be very close to optimal, and often many orders or magnitude better than the most established approaches. As different underlying geometries suit different methods, we also introduce a hyper-optimization approach, where both the method applied and its algorithmic parameters are tuned during the path finding. The increase in quality of contraction schemes found has significant practical implications for the simulation of quantum many-body systems and particularly for the benchmarking of new quantum chips.},
archivePrefix = {arXiv},
arxivId = {2002.01935},
author = {Gray, Johnnie and Kourtis, Stefanos},
eprint = {2002.01935},
file = {:Users/leiwang/Work/Others/Papers/2002.01935.pdf:pdf},
title = {{Hyper-optimized tensor network contraction}},
url = {http://arxiv.org/abs/2002.01935},
year = {2020}
}

@article{Schutski2020,
abstract = {Tensor networks are the main building blocks in a wide variety of computational sciences, ranging from many-body theory and quantum computing to probability and machine learning. Here we propose a parallel algorithm for the contraction of tensor networks using probabilistic graphical models. Our approach is based on the heuristic solution of the {\$}\backslashmu{\$}-treewidth deletion problem in graph theory. We apply the resulting algorithm to the simulation of random quantum circuits and discuss the extensions for general tensor network contractions.},
archivePrefix = {arXiv},
arxivId = {2004.10892},
author = {Schutski, Roman and Kolmakov, Dmitry and Khakhulin, Taras and Oseledets, Ivan},
eprint = {2004.10892},
file = {:Users/leiwang/Library/Application Support/Mendeley Desktop/Downloaded/Schutski et al. - 2020 - Simple heuristics for efficient parallel tensor contraction and quantum circuit simulation.pdf:pdf},
title = {{Simple heuristics for efficient parallel tensor contraction and quantum circuit simulation}},
url = {http://arxiv.org/abs/2004.10892},
year = {2020}
}

@article{Han2018,
abstract = {Generative modeling, which learns joint probability distribution from data and generates samples according to it, is an important task in machine learning and artificial intelligence. Inspired by probabilistic interpretation of quantum physics, we propose a generative model using matrix product states, which is a tensor network originally proposed for describing (particularly one-dimensional) entangled quantum states. Our model enjoys efficient learning analogous to the density matrix renormalization group method, which allows dynamically adjusting dimensions of the tensors and offers an efficient direct sampling approach for generative tasks. We apply our method to generative modeling of several standard data sets including the Bars and Stripes random binary patterns and the MNIST handwritten digits to illustrate the abilities, features, and drawbacks of our model over popular generative models such as the Hopfield model, Boltzmann machines, and generative adversarial networks. Our work sheds light on many interesting directions of future exploration in the development of quantum-inspired algorithms for unsupervised machine learning, which are promisingly possible to realize on quantum devices.},
archivePrefix = {arXiv},
arxivId = {1709.01662},
author = {Han, Zhao-Yu and Wang, Jun and Fan, Heng and Wang, Lei and Zhang, Pan},
doi = {10.1103/PhysRevX.8.031012},
eprint = {1709.01662},
file = {:Users/leiwang/Work/Others/Papers/PhysRevX.8.031012.pdf:pdf},
issn = {21603308},
journal = {Phys. Rev. X},
keywords = {computational physics,condensed matter physics,doi:10.1103/PhysRevX.8.031012 url:https://doi.org/},
number = {3},
pages = {031012},
publisher = {American Physical Society},
title = {{Unsupervised Generative Modeling Using Matrix Product States}},
url = {https://doi.org/10.1103/PhysRevX.8.031012},
volume = {8},
year = {2018}
}

@article{Critch2014,
abstract = {We quantify the representational power of matrix product states (MPS) for entangled qubit systems by giving polynomial expressions in a pure quantum state's amplitudes which hold if and only if the state is a translation invariant matrix product state or a limit of such states. For systems with few qubits, we give these equations explicitly, considering both periodic and open boundary conditions. Using the classical theory of trace varieties and trace algebras, we explain the relationship between MPS and hidden Markov models and exploit this relationship to derive useful parameterizations of MPS. We make four conjectures on the identifiability of MPS parameters.},
archivePrefix = {arXiv},
arxivId = {1210.2812},
author = {Critch, Andrew and Morton, Jason},
eprint = {1210.2812},
issn = {18150659},
journal = {Symmetry, Integr. Geom. Methods Appl.},
keywords = {Matrix product states,Quantum tomography,Trace algebras,Trace varieties},
title = {{Algebraic geometry of matrix product states}},
volume = {10},
url = {https://www.emis.de//journals/SIGMA/2014/095/},
year = {2014}
}

@article{Zhang2009,
abstract = {The vertex cover problem is a prototypical hard combinatorial optimization problem. It was studied in recent years by physicists using the cavity method of statistical mechanics. In this paper, the stability of the finite-temperature replica-symmetric (RS) and the first-step replica-symmetry-broken (1RSB) cavity solutions of the vertex cover problem on random regular graphs of finite vertex degree K are analyzed by population dynamics simulations. We found that (1) the lowest temperature for the RS solution to be stable, TRS (K), is not a monotonic function of K; (2) at relatively large connectivity K and temperature T slightly below the dynamic transition temperature Td (K), the 1RSB solutions with small but non-negative complexity values are stable, and (3) the dynamical transition temperature Td and Kauzmann temperature TK is equal to each other. Similar results are obtained on random Poissonian graphs. {\textcopyright} 2009 The American Physical Society.},
author = {Zhang, Pan and Zeng, Ying and Zhou, Haijun},
doi = {10.1103/PhysRevE.80.021122},
file = {:Users/leiwang/Work/Others/Papers/PhysRevE.80.021122.pdf:pdf},
issn = {15393755},
journal = {Phys. Rev. E},
number = {2},
pages = {021122},
title = {{Stability analysis on the finite-temperature replica-symmetric and first-step replica-symmetry-broken cavity solutions of the random vertex cover problem}},
volume = {80},
year = {2009}
}

@article{Luo2020,
  doi = {10.22331/q-2020-10-11-341},
  url = {https://doi.org/10.22331/q-2020-10-11-341},
  title = {Yao.jl: {E}xtensible, {E}fficient {F}ramework for {Q}uantum {A}lgorithm {D}esign},
  author = {Luo, Xiu-Zhe and Liu, Jin-Guo and Zhang, Pan and Wang, Lei},
  journal = {{Quantum}},
  issn = {2521-327X},
  publisher = {{Verein zur F{\"{o}}rderung des Open Access Publizierens in den Quantenwissenschaften}},
  volume = {4},
  pages = {341},
  month = oct,
  year = {2020}
}

@article{Johnson2011,
abstract = {Many interesting but practically intractable problems can be reduced to that of finding the ground state of a system of interacting spins; however, finding such a ground state remains computationally difficult. It is believed that the ground state of some naturally occurring spin systems can be effectively attained through a process called quantum annealing. If it could be harnessed, quantum annealing might improve on known methods for solving certain types of problem. However, physical investigation of quantum annealing has been largely confined to microscopic spins in condensed-matter systems. Here we use quantum annealing to find the ground state of an artificial Ising spin system comprising an array of eight superconducting flux quantum bits with programmable spin-spin couplings. We observe a clear signature of quantum annealing, distinguishable from classical thermal annealing through the temperature dependence of the time at which the system dynamics freezes. Our implementation can be configured in situ to realize a wide variety of different spin networks, each of which can be monitored as it moves towards a low-energy configuration. This programmable artificial spin network bridges the gap between the theoretical study of ideal isolated spin networks and the experimental investigation of bulk magnetic samples. Moreover, with an increased number of spins, such a system may provide a practical physical means to implement a quantum algorithm, possibly allowing more-effective approaches to solving certain classes of hard combinatorial optimization problems. {\textcopyright} 2011 Macmillan Publishers Limited. All rights reserved.},
author = {Johnson, M. W. and Amin, M. H.S. and Gildert, S. and Lanting, T. and Hamze, F. and Dickson, N. and Harris, R. and Berkley, A. J. and Johansson, J. and Bunyk, P. and Chapple, E. M. and Enderud, C. and Hilton, J. P. and Karimi, K. and Ladizinsky, E. and Ladizinsky, N. and Oh, T. and Perminov, I. and Rich, C. and Thom, M. C. and Tolkacheva, E. and Truncik, C. J.S. and Uchaikin, S. and Wang, J. and Wilson, B. and Rose, G.},
doi = {10.1038/nature10012},
file = {:Users/leiwang/Work/Others/Papers/nature10012.pdf:pdf},
issn = {00280836},
journal = {Nature},
number = {7346},
pages = {194--198},
title = {{Quantum annealing with manufactured spins}},
volume = {473},
year = {2011}
}

@article{Glasser,
abstract = {Tensor networks have found a wide use in a variety of applications in physics and computer science, recently leading to both theoretical insights as well as practical algorithms in machine learning. In this work we explore the connection between tensor networks and probabilistic graphical models, and show that it motivates the definition of generalized tensor networks where information from a tensor can be copied and reused in other parts of the network. We discuss the relationship between generalized tensor network architectures used in quantum physics, such as string-bond states, and architectures commonly used in machine learning. We provide an algorithm to train these networks in a supervised-learning context and show that they overcome the limitations of regular tensor networks in higher dimensions, while keeping the computation efficient. A method to combine neural networks and tensor networks as part of a common deep learning architecture is also introduced. We benchmark our algorithm for several generalized tensor network architectures on the task of classifying images and sounds, and show that they outperform previously introduced tensor-network algorithms. The models we consider also have a natural implementation on a quantum computer and may guide the development of near-term quantum machine learning architectures.},
archivePrefix = {arXiv},
arxivId = {1806.05964},
author = {Glasser, Ivan and Pancotti, Nicola and {Ignacio Cirac}, J.},
doi = {10.1109/ACCESS.2020.2986279},
eprint = {1806.05964},
file = {:Users/leiwang/Work/Others/Papers/1806.05964.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Boltzmann machines,graphical models,machine learning,quantum circuits,string-bond states,supervised learning,tensor networks,tensor-train},
pages = {68169},
title = {{From Probabilistic Graphical Models to Generalized Tensor Networks for Supervised Learning}},
volume = {8},
year = {2020}
}

@article{Guo2019d,
abstract = {Recent advances on quantum computing hardware have pushed quantum computing to the verge of quantum supremacy. Here, we bring together many-body quantum physics and quantum computing by using a method for strongly interacting two-dimensional systems, the projected entangled-pair states, to realize an effective general-purpose simulator of quantum algorithms. The classical computing complexity of this simulator is directly related to the entanglement generation of the underlying quantum circuit rather than the number of qubits or gate operations. We apply our method to study random quantum circuits, which allows us to quantify precisely the memory usage and the time requirements of random quantum circuits. We demonstrate our method by computing one amplitude for a 7Ã—7 lattice of qubits with depth (1+40+1) on the Tianhe-2 supercomputer.},
archivePrefix = {arXiv},
arxivId = {1905.08394},
author = {Guo, Chu and Liu, Yong and Xiong, Min and Xue, Shichuan and Fu, Xiang and Huang, Anqi and Qiang, Xiaogang and Xu, Ping and Liu, Junhua and Zheng, Shenggen and Huang, He Liang and Deng, Mingtang and Poletti, Dario and Bao, Wan Su and Wu, Junjie},
doi = {10.1103/PhysRevLett.123.190501},
eprint = {1905.08394},
file = {:Users/leiwang/Work/Others/Papers/PhysRevLett.123.190501.pdf:pdf},
issn = {10797114},
journal = {Phys. Rev. Lett.},
keywords = {doi:10.1103/PhysRevLett.123.190501 url:https://doi},
number = {19},
pages = {190501},
publisher = {American Physical Society},
title = {{General-Purpose Quantum Circuit Simulator with Projected Entangled-Pair States and the Quantum Supremacy Frontier}},
url = {https://doi.org/10.1103/PhysRevLett.123.190501},
volume = {123},
year = {2019}
}

@article{Kirkpatrick1983,
abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
author = {Kirkpatrick, S. and Gelatt, C. D. and Vecchi, M. P.},
doi = {10.1126/science.220.4598.671},
file = {:Users/leiwang/Work/Others/Papers/kirkpatrick (1983) optimization by simulated annealing.pdf:pdf},
issn = {00368075},
journal = {Science},
number = {4598},
pages = {671--680},
pmid = {17813860},
title = {{Optimization by simulated annealing}},
volume = {220},
year = {1983}
}

@article{Wang2014e,
abstract = {Tensor renormalization group (TRG) method is a real space renormalization group approach. It has been successfully applied to both classical and quantum systems. In this paper, we study a disordered and frustrated system, the two-dimensional Edwards-Anderson model, by a new topological invariant TRG scheme. We propose an approach to calculate the local magnetizations and nearest pair correlations simultaneously. The Nishimori multicritical point predicted by the topological invariant TRG agrees well with the recent Monte Carlo results. The TRG schemes outperform the mean-field methods on the calculation of the partition function. We notice that it might obtain a negative partition function at sufficiently low temperatures. However, the negative contribution can be neglected if the system is large enough. This topological invariant TRG can also be used to study three-dimensional spin glass systems.},
author = {Wang, Chuang and Qin, Shao Meng and Zhou, Hai Jun},
doi = {10.1103/PhysRevB.90.174201},
file = {:Users/leiwang/Work/Others/Papers/PhysRevB.90.174201.pdf:pdf},
issn = {1550235X},
journal = {Phys. Rev. B},
number = {17},
pages = {174201},
title = {{Topologically invariant tensor renormalization group method for the Edwards-Anderson spin glasses model}},
volume = {90},
year = {2014}
}

@article{Dumitrescu2018a,
abstract = {Tensor networks are powerful factorization techniques which reduce resource requirements for numerically simulating principal quantum many-body systems and algorithms. The computational complexity of a tensor network simulation depends on the tensor ranks and the order in which they are contracted. Unfortunately, computing optimal contraction sequences (orderings) in general is known to be a computationally difficult (NP-complete) task. In 2005, Markov and Shi showed that optimal contraction sequences correspond to optimal (minimum width) tree decompositions of a tensor network's line graph, relating the contraction sequence problem to a rich literature in structural graph theory. While treewidth-based methods have largely been ignored in favor of dataset-specific algorithms in the prior tensor networks literature, we demonstrate their practical relevance for problems arising from two distinct methods used in quantum simulation: multi-scale entanglement renormalization ansatz (MERA) datasets and quantum circuits generated by the quantum approximate optimization algorithm (QAOA). We exhibit multiple regimes where treewidth-based algorithms outperform domain-specific algorithms, while demonstrating that the optimal choice of algorithm has a complex dependence on the network density, expected contraction complexity, and user run time requirements. We further provide an open source software framework designed with an emphasis on accessibility and extendability, enabling replicable experimental evaluations and future exploration of competing methods by practitioners.},
author = {Dumitrescu, Eugene F. and Fisher, Allison L. and Goodrich, Timothy D. and Humble, Travis S. and Sullivan, Blair D. and Wright, Andrew L.},
doi = {10.1371/journal.pone.0207827},
file = {:Users/leiwang/Work/Others/Papers/journal.pone.0207827.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS One},
number = {12},
pages = {1--19},
title = {{Benchmarking treewidth as a practical component of tensor network simulations}},
volume = {13},
year = {2018}
}

@article{Vannimenus1977,
abstract = {For pt.I see Commun. Phys., vol.2, p.115 (1977). Presents numerical results for the ground-state properties of the simplest system showing the frustration effect, Ising spins on a square lattice with a variable concentration x of antiferromagnetic interactions. Ferromagnetism disappears at a concentration xc approximately 0.09. The ground-state energy and degeneracy have markedly different behaviours below and above xc. The authors compare the results with other calculations and stress the advantages of the frustration approach.},
author = {Vannimenus, J. and Toulouse, G.},
doi = {10.1088/0022-3719/10/18/008},
file = {:Users/leiwang/Work/Others/Papers/J{\_}Vannimenus{\_}1977{\_}J.{\_}Phys.{\_}C {\_}Solid{\_}State{\_}Phys.{\_}10{\_}008.pdf:pdf},
journal = {J. Phys. C Solid State Phys.},
number = {18},
pages = {L537},
title = {{Theory of the frustration effect. II. Ising spins on a square lattice}},
volume = {10},
year = {1977}
}

@article{Kourtis2018,
abstract = {We introduce tensor network contraction algorithms for counting satisfying assignments of constraint satisfaction problems ({\#}CSPs). We represent each arbitrary {\#}CSP formula as a tensor network, whose full contraction yields the number of satisfying assignments of that formula, and use graph theoretical methods to determine favorable orders of contraction. We employ our heuristics for the solution of {\#}P-hard counting boolean satisfiability ({\#}SAT) problems, namely monotone {\#}1-in-3SAT and {\#}Cubic-Vertex-Cover, and find that they outperform state-of-the-art solvers by a significant margin.},
archivePrefix = {arXiv},
arxivId = {1805.00475},
author = {Kourtis, Stefanos and Chamon, Claudio and Mucciolo, Eduardo and Ruckenstein, Andrei},
doi = {10.21468/scipostphys.7.5.060},
eprint = {1805.00475},
file = {:Users/leiwang/Work/Others/Papers/1805.00475.pdf:pdf},
issn = {2542-4653},
journal = {SciPost Phys.},
number = {5},
title = {{Fast counting with tensor networks}},
url = {http://arxiv.org/abs/1805.00475},
volume = {7},
year = {2019}
}

@article{Wang1988,
  title = {Low-temperature properties of the $\ifmmode\pm\else\textpm\fi{}J$ Ising spin glass in two dimensions},
  author = {Wang, Jian-Sheng and Swendsen, Robert H.},
  journal = {Phys. Rev. B},
  volume = {38},
  issue = {7},
  pages = {4840--4844},
  numpages = {0},
  year = {1988},
  month = {Sep},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.38.4840},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.38.4840}
}


@article{Rams2018a,
abstract = {We devise a deterministic physics-inspired classical algorithm to efficiently reveal the structure of low-energy spectrum for certain low-dimensional spin-glass systems that encode optimization problems. We employ tensor networks to represent Gibbs distribution of all possible configurations. We then develop techniques to extract the relevant information from the networks for quasi-two-dimensional Ising Hamiltonians. Motivated by present-day quantum annealers, we mainly focus on hard structured problems on the chimera graph with up to {\$}2048{\$} spins. To this end, we apply a branch and bound strategy over marginal probability distributions by approximately evaluating tensor contractions. Our approach identifies configurations with the largest Boltzmann weights corresponding to low energy states. Moreover, by exploiting local nature of the problems, we discover spin-glass droplets geometries. This naturally encompasses sampling from high quality solutions within a given approximation ratio. It is thus established that tensor networks techniques can provide profound insight into the structure of disordered spin complexes, with ramifications both for machine learning and noisy intermediate-scale quantum devices. At the same time, limitations of our approach highlight alternative directions to establish quantum speed-up and possible quantum supremacy experiments.},
archivePrefix = {arXiv},
arxivId = {1811.06518},
author = {Rams, Marek M. and Mohseni, Masoud and Gardas, Bart{\l}omiej},
eprint = {1811.06518},
file = {:Users/leiwang/Work/Others/Papers/1811.06518.pdf:pdf},
title = {{Heuristic optimization and sampling with tensor networks for quasi-2D spin glass problems}},
url = {http://arxiv.org/abs/1811.06518},
year = {2018}
}

@article{Biamonte2015,
abstract = {The computational cost of counting the number of solutions satisfying a Boolean formula, which is a problem instance of {\#}SAT, has proven subtle to quantify. Even when finding individual satisfying solutions is computationally easy (e.g. 2-SAT, which is in {\$}{\$}$\backslash$mathsf{\{}{\{}P{\}}{\}}{\$}{\$}P), determining the number of solutions can be {\#}{\$}{\$}$\backslash$mathsf{\{}{\{}P{\}}{\}}{\$}{\$}P-hard. Recently, computational methods simulating quantum systems experienced advancements due to the development of tensor network algorithms and associated quantum physics-inspired techniques. By these methods, we give an algorithm using an axiomatic tensor contraction language for n-variable {\#}SAT instances with complexity {\$}{\$}O((g+cd){\^{}}{\{}O(1){\}} 2{\^{}}c){\$}{\$}O((g+cd)O(1) 2c) where c is the number of COPY-tensors, g is the number of gates, and d is the maximal degree of any COPY-tensor. Thus, n-variable counting problems can be solved efficiently when their tensor network expression has at most {\$}{\$}O($\backslash$log n){\$}{\$}O(logn) COPY-tensors and polynomial fan-out. This framework also admits an intuitive proof of a variant of the Tovey conjecture (the r,1-SAT instance of the Duboisâ€“Tovey theorem). This study increases the theory, expressiveness and application of tensor based algorithmic tools and provides an alternative insight on these problems which have a long history in statistical physics and computer science.},
archivePrefix = {arXiv},
arxivId = {1405.7375},
author = {Biamonte, Jacob D. and Morton, Jason and Turner, Jacob},
doi = {10.1007/s10955-015-1276-z},
eprint = {1405.7375},
file = {:Users/leiwang/Work/Others/Papers/Biamonte2015{\_}Article{\_}TensorNetworkContractionsForSA.pdf:pdf},
issn = {00224715},
journal = {J. Stat. Phys.},
keywords = {Complexity,Computational physics,Quantum physics,Statistical physics},
number = {5},
pages = {1389},
publisher = {Springer US},
title = {{Tensor Network Contractions for {\#}SAT}},
volume = {160},
year = {2015}
}

@article{treewidth,
author = {Markov, Igor and Shi, Yaoyun},
file = {:Users/leiwang/Work/Others/Papers/treewidth-sicomp.pdf:pdf},
journal = {SIAM J. Comput.},
keywords = {classical simula-,computational complexity,one-way quantum computation,quantum computation,tensor network,tion,treewidth},
pages = {963},
title = {{Simulating quantum computation by contracting tensor networks}},
url = {https://epubs.siam.org/doi/10.1137/050644756},
volume = {38},
year = {2008}
}

@article{Villalonga,
abstract = {Noisy Intermediate-Scale Quantum (NISQ) computers are entering an era in which they can perform computational tasks beyond the capabilities of the most powerful classical computers, thereby achieving "Quantum Supremacy", a major milestone in quantum computing. NISQ Supremacy requires comparison with a state-of-the-art classical simulator. We report HPC simulations of hard random quantum circuits (RQC), which have been recently used as a benchmark for the first experimental demonstration of Quantum Supremacy, sustaining an average performance of 281 Pflop/s (true single precision) on Summit, currently the fastest supercomputer in the World. These simulations were carried out using qFlex, a tensor-network-based classical high-performance simulator of RQCs. Our results show an advantage of many orders of magnitude in energy consumption of NISQ devices over classical supercomputers. In addition, we propose a standard benchmark for NISQ computers based on qFlex.},
archivePrefix = {arXiv},
arxivId = {1905.00444},
author = {Villalonga, Benjamin and Lyakh, Dmitry and Boixo, Sergio and Neven, Hartmut and Humble, Travis S and Biswas, Rupak and Rieffel, Eleanor G and Ho, Alan and Mandr{\`{a}}, Salvatore},
doi = {10.1088/2058-9565/ab7eeb},
eprint = {1905.00444},
file = {:Users/leiwang/Work/Others/Papers/1905.00444.pdf:pdf},
issn = {2058-9565},
journal = {Quantum Sci. Technol.},
number = {3},
pages = {034003},
title = {{Establishing the quantum supremacy frontier with a 281 Pflop/s simulation}},
volume = {5},
year = {2020}
}

@article{Dudek2019,
abstract = {Constrained counting is a fundamental problem in artificial intelligence. A promising new algebraic approach to constrained counting makes use of tensor networks, following a reduction from constrained counting to the problem of tensor-network contraction. Contracting a tensor network efficiently requires determining an efficient order to contract the tensors inside the network, which is itself a difficult problem. In this work, we apply graph decompositions to find contraction orders for tensor networks. We prove that finding an efficient contraction order for a tensor network is equivalent to the well-known problem of finding an optimal carving decomposition. Thus memory-optimal contraction orders for planar tensor networks can be found in cubic time. We show that tree decompositions can be used both to find carving decompositions and to factor tensor networks with high-rank, structured tensors. We implement these algorithms on top of state-of-the-art solvers for tree decompositions and show empirically that the resulting weighted model counter is quite effective and useful as part of a portfolio of counters.},
archivePrefix = {arXiv},
arxivId = {1908.04381},
author = {Dudek, Jeffrey M and Due{\~{n}}as-Osorio, Leonardo and Vardi, Moshe Y.},
eprint = {1908.04381},
file = {:Users/leiwang/Library/Application Support/Mendeley Desktop/Downloaded/Dudek, Due{\~{n}}as-Osorio, Vardi - 2019 - Efficient Contraction of Large Tensor Networks for Weighted Model Counting through Graph Decomposi.pdf:pdf},
keywords = {carving decomposition,decomposition,tensor network contraction,tree,weighted model counting},
title = {{Efficient Contraction of Large Tensor Networks for Weighted Model Counting through Graph Decompositions}},
url = {http://arxiv.org/abs/1908.04381},
year = {2019}
}

@article{Aji2000,
abstract = {In this semitutorial paper we discuss a general message passing algorithm, which we call the generalized distributive law (GDL). The GDL is a synthesis of the work of many authors in the information theory, digital communications, signal processing, statistics, and artificial intelligence communities. It includes as special cases the Baum-Welch algorithm, the fast Fourier transform (FFT) on any finite Abelian group, the Gallager-Tanner-Wiberg decoding algorithm, Viterbi's algorithm, the BCJR algorithm, Pearl's "belief propagation" algorithm, the Shafer-Shenoy probability propagation algorithm, and the turbo decoding algorithm. Although this algorithm is guaranteed to give exact answers only in certain cases (the "junction tree" condition), unfortunately not including the cases of GTW with cycles or turbo decoding, there is much experimental evidence, and a few theorems, suggesting that it often works approximately even when it is not supposed to. {\textcopyright} 2000 IEEE.},
author = {Aji, Srinivas M. and McEliece, Robert J.},
doi = {10.1109/18.825794},
file = {:Users/leiwang/Work/Others/Papers/GDL.pdf:pdf},
issn = {00189448},
journal = {IEEE Trans. Inf. Theory},
keywords = {Belief propagation,Distributive law,Graphical models,Junction trees,Turbo codes},
number = {2},
pages = {325--343},
title = {{The generalized distributive law}},
volume = {46},
year = {2000}
}

@misc{github,
 note = {\href{https://github.com/TensorBFS/TropicalTensors.jl}{https://github.com/TensorBFS/TropicalTensors.jl}}
}
@misc{ma,
 note = {\href{https://github.com/YingboMa/MaBLAS.jl}{https://github.com/YingboMa/MaBLAS.jl}}
}

@misc{blog,
 note = {\href{https://matbesancon.github.io/post/2020-01-23-discrete-diff/}{https://matbesancon.github.io/post/2020-01-23-discrete-diff/}}
}


@book{mezard2009information,
  title={Information, physics, and computation},
  author={Mezard, Marc and Montanari, Andrea},
  year={2009},
  publisher={Oxford University Press}
}

@book{koller2009probabilistic,
  title={Probabilistic graphical models: principles and techniques},
  author={Koller, Daphne and Friedman, Nir},
  year={2009},
  publisher={MIT press}
}

@book{maclagan2015introduction,
  title={Introduction to tropical geometry},
  author={Maclagan, Diane and Sturmfels, Bernd},
  volume={161},
  year={2015},
  url = {http://www.cs.technion.ac.il/~janos/COURSES/238900-13/Tropical/MaclaganSturmfels.pdf},
  publisher={American Mathematical Soc.}
}

@article{Garcia-Saez,
author = {Garc\'{\i}a-S\'{a}ez, Artur and Latorre, Jos\'{e} I.},
title = {An Exact Tensor Network for the 3SAT Problem},
year = {2012},
issue_date = {March 2012},
publisher = {Rinton Press, Incorporated},
address = {Paramus, NJ},
volume = {12},
number = {3â€“4},
issn = {1533-7146},
journal = {Quantum Info. Comput.},
url = {https://dl.acm.org/doi/abs/10.5555/2230976.2230984},
month = mar,
pages = {283â€“292},
numpages = {10}
}



@article{valiant1979complexity,
  title={The complexity of enumeration and reliability problems},
  author={Valiant, Leslie G},
  journal={SIAM Journal on Computing},
  volume={8},
  number={3},
  pages={410--421},
  year={1979},
    url = {https://epubs.siam.org/doi/abs/10.1137/0208032},
  publisher={SIAM}
}

@article{chen2018classical,
      title={Classical simulation of intermediate-size quantum circuits},
        author={Chen, Jianxin and Zhang, Fang and Huang, Cupjin and Newman, Michael and Shi, Yaoyun},
eprint = {1805.01450},
url = {http://arxiv.org/abs/1805.01450},
archivePrefix = {arXiv},
year= {2018},
arxivId = {1805.01450}
}

@article{bruteforce,
abstract = {We demonstrate how to compute the low energy spectrum for small ({\$}N\backslashle 50{\$}), but otherwise arbitrary, spin-glass instances using modern Graphics Processing Units or similar heterogeneous architecture. Our algorithm performs an exhaustive (i.e., brute-force) search of all possible configurations to select {\$}S\backslashll 2{\^{}}N{\$} lowest ones together with their corresponding energies. We mainly focus on the Ising model defined on an arbitrary graph. An open-source implementation based on CUDA Fortran and a suitable Python wrapper are provided. As opposed to heuristic approaches, ours is exact and thus can serve as a references point to benchmark other algorithms and hardware, including quantum and digital annealers. Our implementation offers unprecedented speed and efficiency already visible on commodity hardware. At the same time, it can be easily launched on professional, high-end graphics cards virtually at no extra effort. As a practical application, we employ it to demonstrate that the recent Matrix Product State based algorithm-despite its one-dimensional nature-can still accurately approximate the low energy spectrum of fully connected graphs of size {\$}N{\$} approaching {\$}50{\$}.},
archivePrefix = {arXiv},
arxivId = {1904.03621},
author = {Ja{\l}owiecki, Konrad and Rams, Marek M and Gardas, Bart{\l}omiej},
eprint = {1904.03621},
file = {:Users/leiwang/Work/Others/Papers/1904.03621.pdf:pdf},
keywords = {cuda fortran,ising spin-glass,quantum annealers,titan v gpu},
title = {{Brute-forcing spin-glass problems with CUDA}},
url = {http://arxiv.org/abs/1904.03621},
year = {2019}
}

@article{Boixo2014,
abstract = {Quantum technology is maturing to the point where quantum devices, such as quantum communication systems, quantum random number generators and quantum simulators may be built with capabilities exceeding classical computers. A quantum annealer, in particular, solves optimization problems by evolving a known initial configuration at non-zero temperature towards the ground state of a Hamiltonian encoding a given problem. Here, we present results from tests on a 108 qubit D-Wave One device based on superconducting flux qubits. By studying correlations we find that the device performance is inconsistent with classical annealing or that it is governed by classical spin dynamics. In contrast, we find that the device correlates well with simulated quantum annealing. We find further evidence for quantum annealing in the form of small-gap avoided level crossings characterizing the hard problems. To assess the computational power of the device we compare it against optimized classical algorithms. {\textcopyright} 2014 Macmillan Publishers Limited.},
author = {Boixo, Sergio and R{\o}nnow, Troels F. and Isakov, Sergei V. and Wang, Zhihui and Wecker, David and Lidar, Daniel A. and Martinis, John M. and Troyer, Matthias},
doi = {10.1038/nphys2900},
issn = {17452481},
journal = {Nat. Phys.},
number = {3},
pages = {218},
title = {{Evidence for quantum annealing with more than one hundred qubits}},
volume = {10},
year = {2014}
}


@article{Selby2014,
archivePrefix = {arXiv},
arxivId = {1409.3934},
author = {Selby, Alex},
eprint = {1409.3934},
title = {{Efficient subgraph-based sampling of Ising-type models with frustration}},
year = {2014}
}


@inproceedings{shah2013novel,
  title={Novel algebras for advanced analytics in julia},
  author={Shah, Viral B and Edelman, Alan and Karpinski, Stefan and Bezanson, Jeff and Kepner, Jeremy},
  booktitle={2013 IEEE High Performance Extreme Computing Conference (HPEC)},
  pages={1--4},
  year={2013},
  organization={IEEE}
}

@book{stepanov2014mathematics,
  title={From mathematics to generic programming},
  author={Stepanov, Alexander A and Rose, Daniel E},
  year={2014},
  publisher={Pearson Education}
}

@article{Baydin2018,
abstract = {Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply "autodiff", is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational fluid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other's results. Despite its relevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names "dynamic computational graphs" and "differentiable programming". We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main implementation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms "autodiff", "automatic differentiation", and "symbolic differentiation" as these are encountered more and more in machine learning settings.},
archivePrefix = {arXiv},
arxivId = {1502.05767},
author = {Baydin, Atilim Gunes and Pearlmutter, Barak A. and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
doi = {10.1016/j.advwatres.2018.01.009},
eprint = {1502.05767},
file = {:Users/zhangyin/Library/Application Support/Mendeley Desktop/Downloaded/Baydin et al. - 2015 - Automatic differentiation in machine learning a survey.pdf:pdf},
isbn = {0002-9645 (Print)\r0002-9645 (Linking)},
issn = {03091708},
journal = {Journal of Machine Learning},
month = {feb},
number = {14},
pages = {1--43},
pmid = {7020497},
title = {{Automatic differentiation in machine learning: a survey}},
url = {http://jmlr.org/papers/v18/16-107.html http://arxiv.org/abs/1502.05767},
volume = {18},
year = {2015}
}

@article{pauling1935structure,
  title={The structure and entropy of ice and of other crystals with some randomness of atomic arrangement},
  author={Pauling, Linus},
  journal={Journal of the American Chemical Society},
  volume={57},
  number={12},
  pages={2680--2684},
  year={1935},
  publisher={ACS Publications}
}

@article{lauritzen1988local,
  title={Local computations with probabilities on graphical structures and their application to expert systems},
  author={Lauritzen, Steffen L and Spiegelhalter, David J},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={50},
  number={2},
  pages={157--194},
  year={1988},
  publisher={Wiley Online Library}
}

@article{Gao2018,
abstract = {Quantum computing and artificial intelligence, combined together, may revolutionize future technologies. A significant school of thought regarding artificial intelligence is based on generative models. Here, we propose a general quantum algorithm for machine learning based on a quantum generative model. We prove that our proposed model is more capable of representing probability distributions compared with classical generative models and has exponential speedup in learning and inference at least for some instances if a quantum computer cannot be efficiently simulated classically. Our result opens a new direction for quantum machine learning and offers a remarkable example where a quantum algorithm shows exponential improvement over classical algorithms in an important application field.},
author = {Gao, X. and Zhang, Z. Y. and Duan, L. M.},
doi = {10.1126/sciadv.aat9004},
file = {:Users/leiwang/Work/Others/Papers/eaat9004.full.pdf:pdf},
issn = {23752548},
journal = {Sci. Adv.},
pages = {eaat9004},
title = {{A quantum machine learning algorithm based on generative models}},
volume = {4},
year = {2018}
}

@article{Vanderstraeten2018a,
abstract = {We develop a technique for calculating three-dimensional classical partition functions using projected entangled-pair states (PEPS). Our method is based on variational PEPS optimization algorithms for two-dimensional quantum spin systems, and allows us to compute free energies directly in the thermodynamic limit. The main focus of this work is classical frustration in three-dimensional many-body systems leading to an extensive ground-state degeneracy. We provide high-accuracy results for the residual entropy of the dimer model on the cubic lattice, water-ice $I_h$ and water-ice $I_c$. In addition, we show that these systems are in a Coulomb phase by computing the dipolar form of the correlation functions. As a further benchmark of our methods, we calculate the critical temperature and exponents of the Ising model on the cubic lattice.},
archivePrefix = {arXiv},
arxivId = {1805.10598},
author = {Vanderstraeten, Laurens and Vanhecke, Bram and Verstraete, Frank},
doi = {10.1103/PhysRevE.98.042145},
eprint = {1805.10598},
file = {:Users/zhangyin/Library/Application Support/Mendeley Desktop/Downloaded/Vanderstraeten, Vanhecke, Verstraete - 2018 - Residual entropies for three-dimensional frustrated spin systems with tensor networks.pdf:pdf},
issn = {24700053},
journal = {Physical Review E},
number = {4},
pages = {042145},
title = {{Residual entropies for three-dimensional frustrated spin systems with tensor networks}},
volume = {98},
year = {2018}
}

@article{Vanhecke2020a,
abstract = {Classical frustrated spin systems give rise to many fascinating many-body phenomena, but standard computational techniques such as Monte-Carlo sampling or tensor networks have great difficulties in simulating a large variety of them. We propose a framework to map generic frustrated spin systems onto frustration-free models on a correlated phase space, resulting both in an improved analytical understanding of the ground state ensembles via local rules, and a natural construction of a tensor network on which standard algorithms can be used efficiently. The main technical ingredient consists in a linear program identifying large scale degrees of freedom for which the frustration can be relaxed. We illustrate the power of the method by determining the ground-state local rule and computing the residual entropy of a frustrated Ising spin system on the kagome lattice with next-next-nearest neighbour interactions.},
archivePrefix = {arXiv},
arxivId = {2006.14341},
author = {Vanhecke, Bram and Colbois, Jeanne and Vanderstraeten, Laurens and Mila, Fr{\'{e}}d{\'{e}}ric and Verstraete, Frank},
eprint = {2006.14341},
file = {:Users/zhangyin/Paper/2006.14341.pdf:pdf},
title = {{Relaxing Frustration in Classical Spin Systems}},
url = {http://arxiv.org/abs/2006.14341},
year = {2020}
}

@article{edwards1975theory,
  title={Theory of spin glasses},
  author={Edwards, Samuel Frederick and Anderson, Phil W},
  journal={Journal of Physics F: Metal Physics},
  volume={5},
  number={5},
  pages={965},
  year={1975},
  publisher={IOP Publishing}
}

@book{Perumalla2013,
  title={Introduction to reversible computing},
  author={Perumalla, Kalyan S},
  year={2013},
  publisher={CRC Press}
}

@ARTICLE{Kingsbury1971,
  author={N. G. {Kingsbury} and P. J. W. {Rayner}},
  journal={Electronics Letters}, 
  title={Digital filtering using logarithmic arithmetic}, 
  year={1971},
  volume={7},
  number={2},
  pages={56-58},
  url={https://doi.org/10.1049/el:19710039}
}

@article{PhysRevLett.69.2292,
  title = {New approach to spin-glass simulations},
  author = {Berg, Bernd A. and Celik, Tarik},
  journal = {Phys. Rev. Lett.},
  volume = {69},
  issue = {15},
  pages = {2292--2295},
  numpages = {0},
  year = {1992},
  month = {Oct},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.69.2292},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.69.2292}
}

@article{PhysRevE.48.R3221,
  title = {Exact integer algorithm for the two-dimensional \ifmmode\pm\else\textpm\fi{}J Ising spin glass},
  author = {Saul, Lawrence and Kardar, Mehran},
  journal = {Phys. Rev. E},
  volume = {48},
  issue = {5},
  pages = {R3221--R3224},
  numpages = {0},
  year = {1993},
  month = {Nov},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.48.R3221},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.48.R3221}
}


@article{Pan2020,
  title = {Contracting Arbitrary Tensor Networks: General Approximate Algorithm and Applications in Graphical Models and Quantum Circuit Simulations},
  author = {Pan, Feng and Zhou, Pengfei and Li, Sujie and Zhang, Pan},
  journal = {Phys. Rev. Lett.},
  volume = {125},
  issue = {6},
  pages = {060503},
  numpages = {6},
  year = {2020},
  month = {Aug},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.125.060503},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.125.060503}
}
