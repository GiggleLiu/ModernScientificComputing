@def title = "Understanding our computing devices"
# Understanding our computing devices

Scientific computing is a combination of scientific applications, mathematical modeling and high performance computing.
The first lecture focuses on understanding our computing devices and understand how to get high performance from them.

## Computer architechture

The [Von Neumann architecture](https://en.wikipedia.org/wiki/Von_Neumann_architecture) design consists of a Control Unit, Arithmetic and Logic Unit (ALU), Memory Unit, Registers and Inputs/Outputs, while the control unit, ALU, and registers are all contained in a central processing unit (CPU).

[![](/assets/images/arch.png)](/assets/images/arch.png)

As illustrated above (click to make it larger), a modern computer contains the following building blocks
* A CPU
    * A **CPU clock** signal is originally generated by quartz crystal oscillators of about 20MHz or so, and then the frequency is multiplied by one or more phase-locked loops to generate the clock signals for different parts of the system. (such as 4GHz for a CPU core).
    * A **control unit** is circuitry within a computer’s processor that directs operations. It instructs the memory, logic unit, and both output and input devices of the computer on how to respond to the program’s instructions. CPUs and GPUs are examples of devices that use control units.
    * **Registers** are the fastest "storage" shiped with CPU, directly accessible to the processor and works in the same clock rate as the CPU clock. A special type of register, the [Single Instruction, Multiple Data (SIMD)](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data) register, can process multiple data points simultaneously with a single instruction.
    * An [ALU](https://en.wikipedia.org/wiki/Arithmetic_logic_unit) is a combinational digital circuit that performs arithmetic and bitwise operations on integer binary numbers. 
* The [memory hierarchy](https://en.wikipedia.org/wiki/Memory_hierarchy) separates computer storage into a hierarchy based on response time.
* A [system bus](https://en.wikipedia.org/wiki/System_bus) is a single computer bus that connects the major components of a computer system, combining the functions of a data bus to carry information, an address bus to determine where it should be sent or read from, and a control bus to determine its operation.

For GPU computing devices, it also contains
* [General-purpose computing on graphics processing units (GPGPU)](https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units) is the use of a graphics processing unit (GPU), which typically handles computation only for computer graphics, to perform computation in applications traditionally handled by the central processing unit (CPU).

Another type of computing device is the graphical processing unit (GPU).
Modern GPUs are efficient at manipulating computer graphics and image processing.
Their parallel structure makes them more efficient than general-purpose central processing units (CPUs) for algorithms that process large blocks of data in parallel.


A program is compiled to binaries (e.g. 010011...) in the main memory of a computer.
The binary encodes both instructions and data, while a instruction can be an arithematic/logical operation to manipulate data in registers, transfering data from the main memory to registers and vise versa, or branching.
For different computing devices, the supported instruction sets can be very different.


When the binary for your program starts to run, the operating system manages the computing resources by deviding the computing time into slices of length several milliseconds.
The computing device (e.g. a CPU or a GPU) crunches the instructions by loading them from the memory to the instruction register first.
When running an data manipulation instruction, i.e. arithmetic, logical or shift instructions, registers are the only memory it can operate on.
The size of a general purposed register in a 64-bit machine is typically 64 bit while some wide registers for SIMD can be serveral times larger.
There are only tens of such registers in a CPU.
Before doing any arithematic operation, CPU must load the data from the main memory to a register through the system bus, after executing the data manipulation instruction, the result is copied back to the main memory.

The performance is related to the algorithm implementation, the optimization done by the compiler, the scheduling mechanism of your operating system and how fast a processor process instruction.

## Memory bandwidth and latency
Memory bandwidth is the speed of data transmission speed from the main memory to the registers, which is much slower than the speed of computing devices manipulating the data.
To get the designed peak performance from your computing devices, you need to perform a certain number of operations on a data before moving it out of your computing devices.
The expected arithmetic indensity is defined as the ratio between the FLOPS and data rate, which is equal to the number of operations to be done on a data to equate the time spent on data transmission and manipulation.

|     | Intel | NVIDIA A100 |
| --- | --- | --- |
| Peak FP64 GFLOPS   | 179   | 19500   |
| Memory bandwidth (GB/s)   | 45.8   | 1555   |
| Expected arithmetic intensity   | 31   | 100  |
| Latency   |    |   |

> NOTE: FP64 data type uses 8 bytes (or 64 bits) to represent a floating point number. Since Intel does not provide peak GFLOPS information for its CPUs, the Peak FP64 GFLOPS for Intel CPU is measured by benchmarking as will be shown bellow.

Reducing the data transmission time is not the only goal since the memory latency is often the bottleneck of a program.
Memory latency is the time between the data loading requesting and the data is ready to operate. The fundamental reason why memory latency must be small is due to the speed limitation of information propagation, i.e. the speed of light.

> Quiz: Given information can not be propagated in a speed faster than the light and the distance between the memory stick and the CPU is 10cm, what is the lower bound of the time loading a data from the memory to a register?

One of the main differences between CPUs and GPUs are their different approaches to solve the latency issue.
CPUs are highly optimized for reducing the latency, i.e. to solve a task as soon as possible. Engineers designed a complicated 3-level caching system for CPUs that exists in the majority of our modern computers.
Caches belongs to the static random access memory (SRAM), which is much faster to access than the main memory or the dynamic random access memory (DRAM) we talk about in our daily life.
As is illustrated in the figure, by the order of decreasing speed and increasing size, caches include fastest L1 cache working in the same speed as CPU, slower L2 cache, and the slowest L3 cache but still faster than the DRAM.
When loading data from the main memory to a register, the CPU looks up the L1 cache first. If the CPU cannot find the data it is looking for in the L1 cache (or cache miss), it checks the L2 cache and L3 cache in order.
Once the desired data is found in the main memory, not only the required data, but also its physical neighbors are loaded to the caches.
The wisdom behind the caching system is data locality, i.e. whenever a data is used, the data physically close to it has much higher probability to be used than the rest. Locality is particularly true when a program perform elementwise operations to an array with contiguous storage.

When loading a 32/64-bit data from the memory to a register, the computer loads a chunk of data to the caches.
The wisdom behind this design is the locallity of data using, i.e. a data is much more likely to be used if it is physically close to the data currently in use.

GPUs hide the latency issues by launching a lot of threads at the same time.
When one thread gets stuck and waiting, a GPU simply trys to find another thread that is about to execute. Without enough threads, a GPU will be latency bottlenecked.
In Compute Unified Device Architecture (CUDA) programming, the number of CUDA cores determines the number of threads that can be simultaneously executed.
CUDA cores are very similar to CPU cores, while the number of which can easily go up to several thousand, they are not as independent as CPU cores.
The style of the execution of CUDA programs are called single instruction multiple threads (SIMT), in which multiple data can be processed by a single instruction.
While the style how CPU cores work is called multiple instruction multiple data (MIMD), which does not require all threads to execute the same instruction.

## Hands on: Get CPU and memory information
### The computing power of a CPU
In the linux system, the CPU information can be printed by typing `lscpu`.
```
$ lscpu
Architecture:            x86_64
  CPU op-mode(s):        32-bit, 64-bit
  Address sizes:         39 bits physical, 48 bits virtual
  Byte Order:            Little Endian
CPU(s):                  8
  On-line CPU(s) list:   0-7
Vendor ID:               GenuineIntel
  Model name:            Intel(R) Core(TM) i7-10510U CPU @ 1.80GHz
    CPU family:          6
    Model:               142
    Thread(s) per core:  2
    Core(s) per socket:  4
    Socket(s):           1
    Stepping:            12
    CPU max MHz:         4900.0000
    CPU min MHz:         400.0000
    BogoMIPS:            4599.93
    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mc
                         a cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss 
                         ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art
                          arch_perfmon pebs bts rep_good nopl xtopology nonstop_
                         tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cp
                         l vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1
                          sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsav
                         e avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault
                          epb invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced 
                         tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase t
                         sc_adjust sgx bmi1 avx2 smep bmi2 erms invpcid mpx rdse
                         ed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1
                          xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_
                         window hwp_epp md_clear flush_l1d arch_capabilities
Virtualization features: 
  Virtualization:        VT-x
Caches (sum of all):     
  L1d:                   128 KiB (4 instances)
  L1i:                   128 KiB (4 instances)
  L2:                    1 MiB (4 instances)
  L3:                    8 MiB (1 instance)
NUMA:                    
  NUMA node(s):          1
  NUMA node0 CPU(s):     0-7
Vulnerabilities:         
  Itlb multihit:         KVM: Mitigation: VMX disabled
  L1tf:                  Not affected
  Mds:                   Not affected
  Meltdown:              Not affected
  Mmio stale data:       Mitigation; Clear CPU buffers; SMT vulnerable
  Retbleed:              Mitigation; Enhanced IBRS
  Spec store bypass:     Mitigation; Speculative Store Bypass disabled via prctl
                          and seccomp
  Spectre v1:            Mitigation; usercopy/swapgs barriers and __user pointer
                          sanitization
  Spectre v2:            Mitigation; Enhanced IBRS, IBPB conditional, RSB fillin
                         g, PBRSB-eIBRS SW sequence
  Srbds:                 Mitigation; Microcode
  Tsx async abort:       Not affected
```

From the output of `lscpu`, one can see the L1d and L1i are the L1 caches for data and instructions, both having a size of 128 KB.
The L2 and L3 caches are larger, they have size 1 MB and 8 MB respectively.
Depending on the different energy strategy and the payload, the CPU clock rate can vary between 0.4 GHz and 4.9 GHz.
The flags tell the information about the instruction sets, among which the `avx2` instruction set is for the single instruction multiple data (SIMD) parallelism.
It uses a 256 wide register to pack 4 double precision floating point numbers or 8 single precision floating point numbers, and perform multiply and add operation on them in a single CPU clock cycle.

A CPU may have multiple cores, and its theoretical upper bound of computing power can be measured by the number of floating point operations your computing device and perform in one second, namely, in floating point operations per second (FLOPS). For the above CPU, the computing power can be estimated with
```
Computing power of a CPU = 2.9 GHz (CPU clock speed, we use the maximum Turbo frequency)
			  * 2 (multiplication and add can happen at the same CPU clock)
			  * 2 (number of instructions per cycle)
		      * 4 (avx instruction set has a 256 with register, it can
                   crunch 4 vectorized double precision floating point
				   operations at one CPU cycle)
              * 4 (number of cores)
			= ? GFLOPS
```

An easy way to check the single/double precision FLOPS is using the matrix multiplication.
Try the following code in a Julia REPL
```julia
julia> using LinearAlgebra

julia> LinearAlgebra.versioninfo()
BLAS: libblastrampoline.so (f2c_capable)
  --> /home/leo/.julia/juliaup/julia-1.9.0-beta2+0.x64.linux.gnu/bin/../lib/julia/libopenblas64_.so (ILP64)
Threading:
  Threads.threadpoolsize() = 1
  Threads.maxthreadid() = 1
  LinearAlgebra.BLAS.get_num_threads() = 1
Relevant environment variables:
  OPENBLAS_NUM_THREADS = 1

julia> n = 1000
1000

julia> A, B, C = randn(Float64, n, n), randn(Float64, n, n), zeros(Float64, n, n);

julia> BLAS.set_num_threads(1)
julia> @benchmark mul!($C, $A, $B)
BenchmarkTools.Trial: 108 samples with 1 evaluation.
 Range (min … max):  44.629 ms … 55.949 ms  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     46.178 ms              ┊ GC (median):    0.00%
 Time  (mean ± σ):   46.571 ms ±  1.634 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%

        ▁▁█▅▁ ▁
  ▃▃▆▃▆██████▇█▇▇▅▅▃▁▃▄▁▁▃▃▁▄▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▃ ▃
  44.6 ms         Histogram: frequency by time        54.1 ms <

 Memory estimate: 0 bytes, allocs estimate: 0.

julia> BLAS.set_num_threads(4)

julia> @benchmark mul!($C, $A, $B)
BenchmarkTools.Trial: 299 samples with 1 evaluation.
 Range (min … max):  15.252 ms … 26.505 ms  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     16.303 ms              ┊ GC (median):    0.00%
 Time  (mean ± σ):   16.716 ms ±  1.831 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%
```

It can be shown that the computing power of a single thread is at least $1000^3 \times 2 / 0.044629 \approx 44.8 {\rm GFLOPS}$.
The computing time of a carefully implemented matrix multiplication function is dominated by the $1000^3$ multiplication operations and the same amount of addition operations.
Dividing $1000 \times 2$ floating point operations in total by the amount of time in the the unit of seconds is the peak FLOPS.
Here we have used the minimum computing time because the system does not always allocate time slices to the program we want to benchmark, using the minimum time gives us the best approximate to the time we want to measure.

For the parallel execution, although we have 4 CPU cores, the 4-thread computation does not give us a 4 time speed up.
This may have different causes, the cores may share caches, the operating system may not allocate all resources to this specific computing task.


In addition, since we are using intel CPU, MKL is slightly faster than the default OpenBLAS.
If we repeat the above numerical experiment, we will get the following timing information, which measures the peak performance of a CPU more acurately.

```
julia> using MKL

julia> LinearAlgebra.versioninfo()
BLAS: libblastrampoline.so (f2c_capable)
  --> /home/leo/.julia/artifacts/347e4bf25d69805922225ce6bf819ef0b8715426/lib/libmkl_rt.so (ILP64)
  --> /home/leo/.julia/artifacts/347e4bf25d69805922225ce6bf819ef0b8715426/lib/libmkl_rt.so (LP64)
Threading:
  Threads.threadpoolsize() = 1
  Threads.maxthreadid() = 1
  LinearAlgebra.BLAS.get_num_threads() = 4
Relevant environment variables:
  OPENBLAS_NUM_THREADS = 1

julia> BLAS.set_num_threads(1)

julia> @benchmark mul!($C, $A, $B)
BenchmarkTools.Trial: 113 samples with 1 evaluation.
 Range (min … max):  42.150 ms … 50.687 ms  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     44.179 ms              ┊ GC (median):    0.00%
 Time  (mean ± σ):   44.434 ms ±  1.435 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%

         ▅▅▂▂▂▅▂▂▅ ▂▃ █                                        
  ▄▄▁▇▇▄▇████████████▅█▇▄█▄▁▄▇▁▁▅▁▁▁▁▄▄▁▁▄▁▄▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▄ ▄
  42.1 ms         Histogram: frequency by time        50.4 ms <

 Memory estimate: 0 bytes, allocs estimate: 0.

julia> BLAS.set_num_threads(4)

julia> @benchmark mul!($C, $A, $B)
BenchmarkTools.Trial: 281 samples with 1 evaluation.
 Range (min … max):  14.882 ms … 26.696 ms  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     15.791 ms              ┊ GC (median):    0.00%
 Time  (mean ± σ):   17.775 ms ±  3.766 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%

    ▃██▄                                                       
  ▄▇█████▄▃▃▂▁▁▁▃▃▂▂▂▁▂▁▃▂▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▂▃▄▆▆▅▃▃ ▃
  14.9 ms         Histogram: frequency by time        25.4 ms <

 Memory estimate: 0 bytes, allocs estimate: 0.
```

```bash
$ lsmem
RANGE                                  SIZE  STATE REMOVABLE  BLOCK
0x0000000000000000-0x000000007fffffff    2G online       yes   0-15
0x0000000088000000-0x000000008fffffff  128M online       yes     17
0x0000000100000000-0x0000000a6fffffff 37.8G online       yes 32-333

Memory block size:       128M
Total online memory:    39.9G
Total offline memory:      0B
```

### The computing power of a GPU

```bash
$ nvidia-smi
```

The NVIDIA V100 GPU has 5,120 CUDA cores, the theoretical computing power can be computed as
```
NVIDIA V100 GPU single precision FLOPS = 5120 (number of CUDA cores)
    * 1380 (GPU clock rate)
    * 2 (multiplication and add can happen at the same GPU clock)
```


## References
1. [https://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-143.pdf](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-143.pdf)
2. [Youtube video]()
